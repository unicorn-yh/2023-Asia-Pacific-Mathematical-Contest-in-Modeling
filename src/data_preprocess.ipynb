{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Download\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18 ,ResNet18_Weights\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD ,lr_scheduler\n",
    "import torch.cuda\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "%matplotlib inline \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Attachment/Attachment 2/\"\n",
    "data_x = np.array([])\n",
    "data_y = np.array([])\n",
    "index = -1\n",
    "data_limit_for_each_class = 5000\n",
    "for path in os.listdir(data_path):\n",
    "    index += 1\n",
    "    data_count = 0\n",
    "    for img in os.listdir(data_path + path):\n",
    "        data_count += 1\n",
    "        image = cv2.imread(data_path + path + \"/\" + img)\n",
    "        data_x = np.append(data_x, image)\n",
    "        data_y = np.append(data_y, image)\n",
    "        if data_count >= data_limit_for_each_class:\n",
    "            break\n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)\n",
    "print(data_x.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../Attachment/Attachment 2/data_X.txt\",data_x)\n",
    "np.savetxt(\"../Attachment/Attachment 2/data_Y.txt\",data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size1 = 3        # Convolutional Layer 1.\n",
    "num_filters1 = 32\n",
    "filter_size2 = 3         # Convolutional Layer 2.\n",
    "num_filters2 = 32\n",
    "filter_size3 = 3          # Convolutional Layer 3.\n",
    "num_filters3 = 64\n",
    "fc_size = 128             # Number of neurons in fully-connected layer.\n",
    "num_channels = 3\n",
    "img_size = 128\n",
    "img_size_flat = img_size * img_size * num_channels\n",
    "img_shape = (img_size, img_size)\n",
    "classes = ['apple', 'carambola', 'pear', 'plum', 'tomato']\n",
    "num_classes = len(classes)\n",
    "batch_size = 32\n",
    "validation_size = .16\n",
    "# how long to wait after validation loss stops improving before terminating training\n",
    "early_stopping = None  # use None if you don't want to implement early stoping\n",
    "checkpoint_dir = \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = torch.tensor(np.array(data_x))       \n",
    "data_y = torch.tensor(np.array(data_y)).long()    \n",
    "dataset = TensorDataset(data_x, data_y)\n",
    "dataset_size = data_x.size(dim = 0)\n",
    "train_size = int(dataset_size * (1-validation_size))\n",
    "valid_size = int(dataset_size * validation_size)\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "data_loader_train = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "data_loader_valid = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(num_channels, num_filters1, filter_size1, padding=filter_size1//2)\n",
    "        self.conv2 = nn.Conv2d(num_filters1, num_filters2, filter_size2, padding=filter_size2//2)\n",
    "        self.conv3 = nn.Conv2d(num_filters2, num_filters3, filter_size3, padding=filter_size3//2)\n",
    "\n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        # Calculate the size of the flattened layer\n",
    "        self.fc1_size = self._get_conv_output((num_channels, img_size, img_size))\n",
    "        self.fc1 = nn.Linear(self.fc1_size, fc_size)\n",
    "        self.fc2 = nn.Linear(fc_size, num_classes)\n",
    "\n",
    "        # Regularizer\n",
    "        self.regularizer = nn.L2Norm(scale=0.04)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutions and max pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        # Flatten the output for the dense layer\n",
    "        x = x.view(-1, self.fc1_size)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        with torch.no_grad():\n",
    "            input = torch.rand(1, *shape)\n",
    "            output = self._forward_features(input)\n",
    "            return int(np.prod(output.size()))\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "model = ConvNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid():\n",
    "    '''\n",
    "    进行验证，返回模型在验证集上的 accuracy\n",
    "    '''\n",
    "    sum_true = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader_valid:\n",
    "            batch_x, batch_y = data[0].to(device), data[1].to(device)\n",
    "            y_hat = model(batch_x)\n",
    "            y_hat = torch.tensor([torch.argmax(_) for _ in y_hat]).to(device)\n",
    "            sum_true += torch.sum(y_hat == batch_y).float()\n",
    "        return sum_true / valid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10   \n",
    "lr = 0.01\n",
    "loss_function = nn.CrossEntropyLoss()                                       # 设置损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)  # 设置优化器\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    '''\n",
    "    完成一个 epoch 的训练\n",
    "    '''\n",
    "    sum_true = 0\n",
    "    sum_loss = 0.0\n",
    "    max_valid_acc = 0\n",
    "    model.train()\n",
    "    index = 0\n",
    "    total_data = len(data_loader_train)\n",
    "    for data in data_loader_train:\n",
    "        # 可视化训练过程\n",
    "        index += 1\n",
    "        print('Training batch {}/{}'.format(index,total_data),end='\\r')\n",
    "        # 选取对应批次数据的输入和标签\n",
    "        batch_x, batch_y = data[0].to(device), data[1].to(device)\n",
    "        y_hat = model(batch_x)\n",
    "        loss = loss_function(y_hat, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()   # 梯度清零\n",
    "        loss.backward()         # 计算梯度\n",
    "        optimizer.step()        # 更新参数\n",
    "\n",
    "        y_hat = torch.tensor([torch.argmax(_) for _ in y_hat]).to(device)\n",
    "        sum_true += torch.sum(y_hat == batch_y).float()\n",
    "        sum_loss += loss.item()\n",
    "\n",
    "    train_acc = sum_true / train_size\n",
    "    train_loss = sum_loss / train_size\n",
    "\n",
    "    valid_acc = valid()\n",
    "    if valid_acc > max_valid_acc:\n",
    "        torch.save(model, \"checkpoint.pt\")\n",
    "\n",
    "    print(f\"epoch: {epoch}, train loss: {train_loss:.4f}, train accuracy: {train_acc*100:.2f}%, valid accuracy: {valid_acc*100:.2f}%, time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()) }\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
